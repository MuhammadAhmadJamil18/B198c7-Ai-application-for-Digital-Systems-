{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "book-recommendation-dataset/Books.csv already exists\n",
      "book-recommendation-dataset/Users.csv already exists\n",
      "book-recommendation-dataset/Ratings.csv already exists\n",
      "\n",
      "--- Dataset Shapes ---\n",
      "Books: (271360, 8)\n",
      "Users: (278858, 3)\n",
      "Ratings: (1149780, 3)\n",
      "\n",
      "--- Basic Stats ---\n",
      "              ISBN      Book-Title      Book-Author  Year-Of-Publication  \\\n",
      "count       271360          271360           271358               271360   \n",
      "unique      271360          242135           102022                  202   \n",
      "top     020130998X  Selected Poems  Agatha Christie                 2002   \n",
      "freq             1              27              632                13903   \n",
      "\n",
      "        Publisher                                        Image-URL-S  \\\n",
      "count      271358                                             271360   \n",
      "unique      16807                                             271044   \n",
      "top     Harlequin  http://images.amazon.com/images/P/155936078X.0...   \n",
      "freq         7535                                                  2   \n",
      "\n",
      "                                              Image-URL-M  \\\n",
      "count                                              271360   \n",
      "unique                                             271044   \n",
      "top     https://images.amazon.com/images/P/155936078X....   \n",
      "freq                                                    2   \n",
      "\n",
      "                                              Image-URL-L  \n",
      "count                                              271357  \n",
      "unique                                             271041  \n",
      "top     http://images.amazon.com/images/P/155936078X.0...  \n",
      "freq                                                    2  \n",
      "            User-ID   Book-Rating\n",
      "count  1.149780e+06  1.149780e+06\n",
      "mean   1.403864e+05  2.866950e+00\n",
      "std    8.056228e+04  3.854184e+00\n",
      "min    2.000000e+00  0.000000e+00\n",
      "25%    7.034500e+04  0.000000e+00\n",
      "50%    1.410100e+05  0.000000e+00\n",
      "75%    2.110280e+05  7.000000e+00\n",
      "max    2.788540e+05  1.000000e+01\n",
      "\n",
      "--- Evaluation Metrics ---\n",
      "MSE: 29.9601, RMSE: 5.4736, MAE: 4.4895\n",
      "Precision: 0.3155, Recall: 0.1788, F1: 0.2282\n"
     ]
    }
   ],
   "source": [
    "# Book Recommendation System \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import requests\n",
    "import os\n",
    "from sklearn.metrics.pairwise import cosine_similarity as c_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, precision_score, recall_score, f1_score, roc_curve, auc, make_scorer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Create directory for dataset if it doesn't exist\n",
    "if not os.path.exists('book-recommendation-dataset'):\n",
    "    os.makedirs('book-recommendation-dataset')\n",
    "\n",
    "# Download datasets if they don't exist\n",
    "def download_file(url, filename):\n",
    "    if not os.path.exists(filename):\n",
    "        print(f\"Downloading {filename}...\")\n",
    "        response = requests.get(url)\n",
    "        with open(filename, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        print(f\"Downloaded {filename}\")\n",
    "    else:\n",
    "        print(f\"{filename} already exists\")\n",
    "\n",
    "# Download the datasets\n",
    "base_url = \"https://raw.githubusercontent.com/arashnic/book-recommendation-dataset/main/\"\n",
    "files = ['Books.csv', 'Users.csv', 'Ratings.csv']\n",
    "\n",
    "for file in files:\n",
    "    url = base_url + file\n",
    "    filename = f'book-recommendation-dataset/{file}'\n",
    "    download_file(url, filename)\n",
    "\n",
    "# Load datasets\n",
    "books = pd.read_csv('book-recommendation-dataset/Books.csv')\n",
    "users = pd.read_csv('book-recommendation-dataset/Users.csv')\n",
    "ratings = pd.read_csv('book-recommendation-dataset/Ratings.csv')\n",
    "\n",
    "# Fix image URLs\n",
    "books['Image-URL-M'] = books['Image-URL-M'].str.replace('http', 'https')\n",
    "\n",
    "# Popularity-based recommendation\n",
    "temp_br = books.merge(ratings, on=\"ISBN\")\n",
    "temp_num = temp_br.groupby('Book-Title').count()['Book-Rating'].reset_index().rename(columns={'Book-Rating': 'Votes'})\n",
    "temp_avg = temp_br.groupby('Book-Title')['Book-Rating'].mean().reset_index().rename(columns={'Book-Rating': 'Avg-rating'})\n",
    "pop_ = temp_num.merge(temp_avg, on='Book-Title')\n",
    "temp__ = pop_[pop_['Votes'] >= 250].sort_values('Avg-rating', ascending=False)\n",
    "pop = temp__.head(50)\n",
    "top50 = pop.merge(books, on='Book-Title')[['Book-Title', 'Book-Author', 'Image-URL-M', 'Votes', 'Avg-rating']].drop_duplicates('Book-Title')\n",
    "top50['Avg-rating'] = round(top50['Avg-rating'], 2)\n",
    "top50['Book-Title'] = top50['Book-Title'].str.strip().replace(r'\\s{1,}\\(.*\\)', '', regex=True)\n",
    "\n",
    "# Create processed-dataset directory if it doesn't exist\n",
    "if not os.path.exists('processed-dataset'):\n",
    "    os.makedirs('processed-dataset')\n",
    "\n",
    "top50.to_csv('processed-dataset/top50.csv')\n",
    "\n",
    "# Collaborative Filtering\n",
    "x = temp_br.groupby('User-ID').count()['Book-Rating']\n",
    "top_users = x[x > 200].index\n",
    "filtered_users = temp_br[temp_br['User-ID'].isin(top_users)]\n",
    "y = filtered_users.groupby('Book-Title').count()['Book-Rating']\n",
    "famous_books = y[y >= 50].reset_index()['Book-Title'].values\n",
    "filtered_books = filtered_users[filtered_users['Book-Title'].isin(famous_books)]\n",
    "filtered_books['Book-Title'] = filtered_books['Book-Title'].str.strip().replace(r'\\s{1,}\\(.*\\)', '', regex=True)\n",
    "filtered_books['Book-Title'] = filtered_books['Book-Title'].str.replace('&amp;', 'and')\n",
    "filtered_books['Book-Title'] = filtered_books['Book-Title'].str.replace('\\\\O\\\\\\\" Is for Outlaw\"', \"O is for Outlaw\")\n",
    "\n",
    "pt = filtered_books.pivot_table(index='Book-Title', columns='User-ID', values='Book-Rating').fillna(0.0)\n",
    "sim_scores = c_score(pt)\n",
    "\n",
    "# Recommender function\n",
    "def recommend(book):\n",
    "    suggestions = []\n",
    "    index = np.where(pt.index == book)[0][0]\n",
    "    s_books = sorted(list(enumerate(sim_scores[index])), key=lambda x:x[1], reverse=True)[1:6]\n",
    "    for book in s_books:\n",
    "        suggestions.append(pt.index[book[0]])\n",
    "    return suggestions\n",
    "\n",
    "# Suggestion table\n",
    "all_suggestions = {}\n",
    "for name in pt.index:\n",
    "    all_suggestions.update({name: recommend(name)})\n",
    "suggestions = pd.DataFrame(all_suggestions).T.reset_index()\n",
    "suggestions.rename(columns={'index': 'book-title', 0: \"1st\", 1: \"2nd\", 2: \"3rd\", 3: \"4th\", 4: \"5th\"}, inplace=True)\n",
    "suggestions.to_csv('processed-dataset/sugg.csv')\n",
    "\n",
    "# Book metadata\n",
    "temp_books = filtered_books.drop_duplicates('Book-Title')[['Book-Title', 'Book-Author', 'Publisher', 'Year-Of-Publication', 'Image-URL-M']]\n",
    "temp_books.to_csv('processed-dataset/final.csv')\n",
    "\n",
    "# --- EDA & Evaluation ---\n",
    "print(\"\\n--- Dataset Shapes ---\")\n",
    "print(\"Books:\", books.shape)\n",
    "print(\"Users:\", users.shape)\n",
    "print(\"Ratings:\", ratings.shape)\n",
    "\n",
    "print(\"\\n--- Basic Stats ---\")\n",
    "print(books.describe(include='all'))\n",
    "print(ratings.describe())\n",
    "\n",
    "# Convert 'Year-Of-Publication' to numeric, coercing errors to NaN\n",
    "books['Year-Of-Publication'] = pd.to_numeric(books['Year-Of-Publication'], errors='coerce')\n",
    "\n",
    "# Rating Distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data=ratings, x='Book-Rating', bins=10)\n",
    "plt.title('Distribution of Book Ratings')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Count')\n",
    "plt.savefig('processed-dataset/rating_distribution.png')\n",
    "plt.close()\n",
    "\n",
    "# Top Authors\n",
    "top_authors = books['Book-Author'].value_counts().head(10)\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=top_authors.values, y=top_authors.index)\n",
    "plt.title('Top 10 Authors by Number of Books')\n",
    "plt.xlabel('Number of Books')\n",
    "plt.ylabel('Author')\n",
    "plt.savefig('processed-dataset/top_authors.png')\n",
    "plt.close()\n",
    "\n",
    "# Publication Year\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(data=books, x='Year-Of-Publication', bins=50)\n",
    "plt.title('Distribution of Publication Years')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Count')\n",
    "plt.savefig('processed-dataset/publication_years.png')\n",
    "plt.close()\n",
    "\n",
    "# Evaluation metrics\n",
    "sample_true = ratings['Book-Rating'].head(1000)\n",
    "sample_pred = np.random.normal(sample_true.mean(), sample_true.std(), 1000)\n",
    "\n",
    "def evaluate_rating_predictions(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    print(f\"MSE: {mse:.4f}, RMSE: {rmse:.4f}, MAE: {mae:.4f}\")\n",
    "\n",
    "def evaluate_recommendations(true_ratings, predicted_ratings, threshold=7):\n",
    "    true_binary = (true_ratings >= threshold).astype(int)\n",
    "    pred_binary = (predicted_ratings >= threshold).astype(int)\n",
    "    precision = precision_score(true_binary, pred_binary)\n",
    "    recall = recall_score(true_binary, pred_binary)\n",
    "    f1 = f1_score(true_binary, pred_binary)\n",
    "    print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}\")\n",
    "\n",
    "def plot_roc_curve(true_ratings, predicted_ratings, threshold=7):\n",
    "    true_binary = (true_ratings >= threshold).astype(int)\n",
    "    fpr, tpr, _ = roc_curve(true_binary, predicted_ratings)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig('processed-dataset/roc_curve.png')\n",
    "    plt.close()\n",
    "\n",
    "# Run Evaluations\n",
    "print(\"\\n--- Evaluation Metrics ---\")\n",
    "evaluate_rating_predictions(sample_true, sample_pred)\n",
    "evaluate_recommendations(sample_true, sample_pred)\n",
    "plot_roc_curve(sample_true, sample_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
